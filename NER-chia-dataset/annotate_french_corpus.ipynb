{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**French corpus annotation using xlm-roberta-base fine tuned model for NER on Chia dataset**\n",
    "\n",
    "Now, once we have trained the NER model on the Chia dataset, we are going to annotate the french translations of the corpus using the model. \n",
    "\n",
    "Remember that the main hypothesis for this annotation strategy is that a multilingual model, such as xlm-roberta-base, fine-tuned for a specific task (NER) in one of the languages it has been trained on, will be able to perfom well in the rest of the languages it has seen during pretraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if working in colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if using colab\n",
    "# !pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "# !pip install -q -U datasets\n",
    "# !pip install -q -U git+https://github.com/huggingface/accelerate.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict for the entities (entity to int value)\n",
    "sel_ent = {\n",
    "    \"O\": 0,\n",
    "    \"B-Condition\": 1,\n",
    "    \"I-Condition\": 2,\n",
    "    \"B-Value\": 3,\n",
    "    \"I-Value\": 4,\n",
    "    \"B-Drug\": 5,\n",
    "    \"I-Drug\": 6,\n",
    "    \"B-Procedure\": 7,\n",
    "    \"I-Procedure\": 8,\n",
    "    \"B-Measurement\": 9,\n",
    "    \"I-Measurement\": 10,\n",
    "    \"B-Temporal\": 11,\n",
    "    \"I-Temporal\": 12,\n",
    "    \"B-Observation\": 13,\n",
    "    \"I-Observation\": 14,\n",
    "    \"B-Person\": 15,\n",
    "    \"I-Person\": 16\n",
    "}\n",
    "entities_list = list(sel_ent.keys())\n",
    "sel_ent_inv = {v: k for k, v in sel_ent.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "root_path = '..' # comment if working in colab\n",
    "# root_path = './drive/MyDrive/HandsOn-NLP' # uncomment if working in colab\n",
    "data_path = f'{root_path}/data'\n",
    "french_data_path = f'{data_path}/chia_criteria_french'\n",
    "french_annotated_path = f'{data_path}/chia_criteria_french_annotated'\n",
    "models_path = f'{root_path}/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = 'xlm-roberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = torch.load(f'{models_path}/chia-multilingual-ner.pt')\n",
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all french texts\n",
    "files = os.listdir(french_data_path)\n",
    "sentences = []\n",
    "\n",
    "for file in files:\n",
    "    with open(f'{french_data_path}/{file}', 'r') as f:\n",
    "        sentences.extend([(file,sentence[:-1])  for sentence in f.readlines() if sentence != '\\n'])\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean all sentences (remove spaces before special characters...)\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s([?.!\"](?:\\s|$))', r'\\1', text)\n",
    "    text = re.sub(r'\\s([,;:])(?:\\s|$)', r'\\1', text)\n",
    "    text = re.sub(r'\\s([)(])', r'\\1', text)\n",
    "    text = re.sub(r'\\s([/])\\s', r'\\1', text)\n",
    "    text = re.sub(r'\\s([%])\\s', r'\\1', text)\n",
    "    text = re.sub(r'\\s([=])\\s', r'\\1', text)\n",
    "    text = re.sub(r'\\s([-])\\s', r'\\1', text)\n",
    "    text = re.sub(r'\\s([+])\\s', r'\\1', text)\n",
    "    text = re.sub(r'\\s([*])\\s', r'\\1', text)\n",
    "    return text\n",
    "\n",
    "sentences = [(file, clean_text(sentence)) for file,sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adolescent(',\n",
       " '10-21',\n",
       " 'ans)',\n",
       " 'en',\n",
       " 'cours',\n",
       " 'de',\n",
       " 'fusion',\n",
       " 'de',\n",
       " 'la',\n",
       " 'colonne',\n",
       " 'vertébrale',\n",
       " 'pour',\n",
       " 'la',\n",
       " 'scoliose',\n",
       " 'idiopathique,',\n",
       " 'la',\n",
       " 'spondylolisthésis',\n",
       " 'ou',\n",
       " 'la',\n",
       " 'kyphose',\n",
       " 'de',\n",
       " 'Scheuermann.']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0][1].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'file'],\n",
       "    num_rows: 296\n",
       "})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_french = []\n",
    "for file, sentence in sentences:\n",
    "    data_french.append({\n",
    "        'tokens': sentence.split(),\n",
    "        'file': file\n",
    "    })\n",
    "data_french = Dataset.from_pandas(pd.DataFrame(data_french))\n",
    "data_french"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentence(sentence, tokenizer):\n",
    "    \"\"\"\n",
    "    Tokenize a sentence using the tokenizer and keeps the word ids\n",
    "    inputs:\n",
    "        sentence: str, sentence to tokenize\n",
    "        tokenizer: tokenizer, tokenizer to use\n",
    "    outputs:\n",
    "        tokenized_sentence: dict, tokenized sentence\n",
    "    \"\"\"\n",
    "    tokenized_sentence = tokenizer(sentence, is_split_into_words=True, truncation=True, padding='max_length', max_length=512)\n",
    "    words_ids  = []\n",
    "    for i in range(len(sentence)):\n",
    "        word_ids_sentence = tokenized_sentence.word_ids(batch_index=i)\n",
    "        words_ids.append(word_ids_sentence)\n",
    "    tokenized_sentence['word_ids'] = words_ids\n",
    "    return tokenized_sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb6079bc1b247b7995ca7f72966fe90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_french = data_french.map(lambda x: tokenize_sentence(x['tokens'], tokenizer), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'file', 'input_ids', 'attention_mask', 'word_ids'],\n",
       "    num_rows: 296\n",
       "})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_french"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get just the input_ids and attention_mask\n",
    "data_for_model = data_french.remove_columns(['file', 'tokens', 'word_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(data_for_model, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_sentences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaForTokenClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:02<00:00,  3.29s/it]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for batch in tqdm(data_loader):\n",
    "    \n",
    "    batch['input_ids'] = torch.LongTensor(np.column_stack(np.array(batch['input_ids']))).to(device)\n",
    "    batch['attention_mask'] = torch.LongTensor(np.column_stack(np.array(batch['attention_mask']))).to(device)\n",
    "    batch_tokenizer = {'input_ids': batch['input_ids'], 'attention_mask': batch['attention_mask']}\n",
    "    # break\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch_tokenizer)\n",
    "    \n",
    "    labels_batch = torch.argmax(outputs.logits, dim=2).to('cpu').numpy()\n",
    "    labels.extend([list(labels_batch[i]) for i in range(labels_batch.shape[0])])\n",
    "    \n",
    "    del batch\n",
    "    del outputs\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NCT02464813_inc.bio_fr.txt',\n",
       " 'Adolescent( 10-21 ans) en cours de fusion de la colonne vertébrale pour la scoliose idiopathique, la spondylolisthésis ou la kyphose de Scheuermann.')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 0, 1, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 9, 10, 10, 10, 10, 11, 12, 13, 13, 13, 14, 14, 14, 14, 14, 15, 16, 16, 16, 16, 16, 16, 16, 17, 18, 19, 19, 19, 20, 21, 21, 21, 21, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "print(data_french[0]['word_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-Procedure', 'B-Person', 'I-Person', 'B-Value', 'I-Value', 'I-Value', 'O', 'O', 'O', 'O', 'B-Procedure', 'I-Procedure', 'I-Procedure', 'I-Procedure', 'I-Procedure', 'I-Procedure', 'I-Procedure', 'I-Procedure', 'I-Procedure', 'O', 'O', 'B-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'O', 'O', 'B-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'O', 'O', 'B-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'O', 'I-Condition', 'I-Condition', 'B-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'I-Condition']\n"
     ]
    }
   ],
   "source": [
    "print([entities_list[l] for l in labels[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_sentences(dataset, labels, entities_list,criteria = 'first_label'):\n",
    "    \"\"\"\n",
    "    Annotate the sentences with the predicted labels\n",
    "    inputs:\n",
    "        dataset: dataset, dataset with the sentences\n",
    "        labels: list, list of labels\n",
    "        entities_list: list, list of entities\n",
    "        criteria: str, criteria to use to select the label when the words pices have different labels\n",
    "            - first_label: select the first label\n",
    "            - majority: select the label with the majority\n",
    "    outputs:\n",
    "        annotated_sentences: list, list of annotated sentences\n",
    "    \"\"\"\n",
    "    annotated_sentences = []\n",
    "    for i in range(len(dataset)):\n",
    "        # get just the tokens different from None\n",
    "        sentence = dataset[i]\n",
    "        word_ids = sentence['word_ids']\n",
    "        sentence_labels = labels[i]\n",
    "        annotated_sentence = [[] for _ in range(len(dataset[i]['tokens']))]\n",
    "        for word_id, label in zip(word_ids, sentence_labels):\n",
    "            if word_id is not None:\n",
    "                annotated_sentence[word_id].append(label)\n",
    "        annotated_sentence_filtered = []\n",
    "        if criteria == 'first_label':\n",
    "            annotated_sentence_filtered = [annotated_sentence[i][0] for i in range(len(annotated_sentence))]\n",
    "        elif criteria == 'majority':\n",
    "            annotated_sentence_filtered = [max(set(annotated_sentence[i]), key=annotated_sentence[i].count) for i in range(len(annotated_sentence))]\n",
    "\n",
    "        annotated_sentences.append(annotated_sentence_filtered)\n",
    "    return annotated_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_sentences_first = annotate_sentences(data_french, labels, entities_list, criteria='first_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_sentences_max = annotate_sentences(data_french, labels, entities_list, criteria='majority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_annotated = Dataset.from_dict({'tokens': data_french['tokens'], 'annotated_labels': annotated_sentences_first, 'annotated_labels_max': annotated_sentences_max, 'file': data_french['file']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'annotated_labels', 'annotated_labels_max', 'file'],\n",
       "    num_rows: 296\n",
       "})"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737a77fd79a142c2bfd26c38ca3e75c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec89713e3df045ccaed01692b61180db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6a2d8a56c645789df35c78890b4bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3475ccb34ee34bc7a39f69d107d161af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2990b55e6a2b42c3a91fa62bafc29684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1894707638374fa6bae0ca010a0b50f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b537014f2144ea9c81cbf43e8ce9ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d999d15f71b4750aac5e9b682c580a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59c364cae7e4b55ac25cb18c8242420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eaf274865c34d48b30b2cc8986f97f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f859327ab74742a697dc1ef32c78137a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7449d58c9d1d49a0b642f3ed720dafba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da6a233be3e4748a62e9f4fa3e78c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70822721a64f4d04a5f019c73e0dc2d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e80ccf522524bb48a3f5e7f78a0f3d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd8d50c77444c4c8fa8fa37fe5cf924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4832502937a4e71adf06112716787ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89b6f9e4e734a7b90ff5b631d31ddce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f621f7ae7f2456c833f4ed9e40b0307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016edb5406284549b08c99a9dfd05adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0dbc267a3b9408391324a0a4198eff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e257e6b2bf43b1bc4cba2fca7ef51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b05ce1bcb44f1ab45750db3d7eb7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291df48bc76648d2afcd9e8c7288c863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7086a20adac9434085ab58fbd1be75f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f694c14f384da9a4cac48ea79b3e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e205e85a0a4148c18e7e9a7ae77e69f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf74bb87ebcd4f70b977526397443bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3708c8811efe4df3a8b74ca8a2ba26c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe9fef9dafd4bd2881d1ab49f1655e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bbe5a9e2ef4813beba57881351102e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf44ce4cc2e43c082ac00abae15f5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "841c4ccd12234f5bad873b0ffd269ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf009f51c639406dbc1c0a5d59abb016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c1d5c944284b3faa3a3ee9ac439fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29817fcd9b4542ff8ef49c36590f57e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a4b321dc214e0b87abd9bffa8a10bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac66e3d3e6964e50b38c7565f94329c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d5b53d1e28466ebed98276e87d3b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6490fa7e384a62a26e2713697e5e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2233ef2fae1041a3bc7e364fe369b6fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61adf7b2473e480b94c4deb1cf94e1b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00aad80128764f79bbcd6dfa2b49e742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd2ad825a1940ff8aac079c06ba49c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0bea43e771440d9f5733b837b148a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659be2266ece482fbae43f88372e65d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec63bd0672c4516a500b048fba9c2a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86429bb6cde24fe5896208ac85c10708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4d35663c46438fb1754b621a508ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/296 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate the files\n",
    "for file in set(dataset_annotated['file']):\n",
    "    file_data = dataset_annotated.filter(lambda x: x['file'] == file)\n",
    "    with open(f'{french_annotated_path}/{file}', 'w') as f:\n",
    "        for sentence, labels, labels_max in zip(file_data['tokens'], file_data['annotated_labels'], file_data['annotated_labels_max']):\n",
    "            for token, label, label_max in zip(sentence, labels, labels_max):\n",
    "                f.write(f'{token} {entities_list[label]} {entities_list[label_max]}\\n')\n",
    "            f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "honlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
